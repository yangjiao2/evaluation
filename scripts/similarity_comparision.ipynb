{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from bert_score import score\n",
    "import torch\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-09T17:42:09.673178Z",
     "start_time": "2024-09-09T17:42:09.667593Z"
    }
   },
   "id": "33b4723472e9de01",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from bert_score import score\n",
    "import torch\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fcc4be41c02467f3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bert_score import score\n",
    "import torch\n",
    "\n",
    "def read_excel_first_sheet(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads the first sheet of an Excel file into a DataFrame.\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(file_path, sheet_name=0)  # 'sheet_name=0' reads the first sheet\n",
    "    return df\n",
    "\n",
    "def add_bert_f1_to_dataframe(df: pd.DataFrame, col1: str, col2: str, score_col: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds a new column with BERT F1 scores to the DataFrame.\n",
    "    \"\"\"\n",
    "    # Extract the ground truth and predicted columns from the DataFrame\n",
    "    gt_list = df[col1].tolist()\n",
    "    print (gt_list)\n",
    "    pt_list = df[col2].tolist()\n",
    "    \n",
    "    print (pt_list)\n",
    "    # Calculate BERT F1 scores\n",
    "    _, _, f1 = score(gt_list, pt_list, lang=\"en\", model_type=\"bert-base-uncased\", batch_size=64)\n",
    "    \n",
    "    # Convert the torch.Tensor to a list and add it as a new column\n",
    "    df[score_col] = f1.tolist()\n",
    "    \n",
    "    return df\n",
    "\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from bert_score import score\n",
    "import torch\n",
    "\n",
    "def add_pairwise_bert_f1_to_dataframe(df: pd.DataFrame, columns: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds new columns with BERT F1 scores for each pairwise combination of the specified columns.\n",
    "    The new columns are named '<col1>:<col2>'.\n",
    "    \n",
    "    :param df: The input DataFrame.\n",
    "    :param columns: A list of four column names to compare pairwise.\n",
    "    :return: The DataFrame with new BERT F1 score columns added.\n",
    "    \"\"\"\n",
    "    # Generate all pairwise combinations of the columns\n",
    "    pairs = list(combinations(columns, 2))\n",
    "    print (pairs)\n",
    "    # For each pair of columns, calculate BERT F1 scores and add as new columns\n",
    "    for col1, col2 in pairs:\n",
    "        \n",
    "        gt_list = df[col1].tolist()\n",
    "        pt_list = df[col2].tolist()\n",
    "   \n",
    "        # Calculate BERT F1 scores for the pair\n",
    "        _, _, f1 = score([str(g) for g in gt_list], [str(p) for p in pt_list], lang=\"en\", model_type=\"bert-base-uncased\", batch_size=64)\n",
    "        \n",
    "        # Add the F1 scores as a new column with the name \"<col1>:<col2>\"\n",
    "        score_col = f\"{col1}:{col2}\"\n",
    "        df[score_col] = f1.tolist()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def update_excel_with_pairwise_bert_f1(input_excel: str, columns: list, output_excel: str = None):\n",
    "    \"\"\"\n",
    "    Reads the first sheet of an Excel file, adds pairwise BERT F1 scores for four columns, \n",
    "    and saves the updated DataFrame back to Excel.\n",
    "    \n",
    "    :param input_excel: Path to the input Excel file.\n",
    "    :param columns: A list of four column names to compare pairwise.\n",
    "    :param output_excel: Path to the output Excel file. If None, overwrites the input file.\n",
    "    \"\"\"\n",
    "    # Step 1: Read the first sheet of the Excel file\n",
    "    df = read_excel_first_sheet(input_excel)\n",
    "    \n",
    "    # Step 2: Add pairwise BERT F1 scores to the DataFrame\n",
    "    df = add_pairwise_bert_f1_to_dataframe(df, columns)\n",
    "    \n",
    "    # Step 3: Save the updated DataFrame back to Excel\n",
    "    if output_excel is None:\n",
    "        output_excel = input_excel\n",
    "    \n",
    "    with pd.ExcelWriter(output_excel, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "        df.to_excel(writer, index=False, sheet_name='Sheet1')  # Save back to the first sheet\n",
    "    \n",
    "    print(f\"Updated Excel file saved to {output_excel}\")\n",
    "\n",
    "# Example usage:\n",
    "# update_excel_with_pairwise_bert_f1('input.xlsx', ['col1', 'col2', 'col3', 'col4'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-11T21:24:35.083662Z",
     "start_time": "2024-09-11T21:24:34.978728Z"
    }
   },
   "id": "c5b891ef0235014f",
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Response_1', 'Response_2'), ('Response_1', 'Response_3'), ('Response_1', 'Response_4'), ('Response_2', 'Response_3'), ('Response_2', 'Response_4'), ('Response_3', 'Response_4')]\n",
      "Updated Excel file saved to consistency.xlsx\n"
     ]
    }
   ],
   "source": [
    "update_excel_with_pairwise_bert_f1('consistency.xlsx', ['Response_1', 'Response_2', 'Response_3', 'Response_4'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-11T21:38:30.855906Z",
     "start_time": "2024-09-11T21:33:41.935512Z"
    }
   },
   "id": "2504f1cf94f053ac",
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# update_excel_with_pairwise_bert_f1('nvinfo_consistency_before.xlsx', ['Response1', 'Response2', 'Response3', 'Response4'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-10T15:20:29.111807Z",
     "start_time": "2024-09-10T15:20:29.109451Z"
    }
   },
   "id": "28056a5f8e38b773",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "SEPERATOR = \":\"\n",
    "\n",
    "\n",
    "def find_max_count(strings):\n",
    "    # Count occurrences of each string in the list\n",
    "    string_counts = Counter(strings)\n",
    "    \n",
    "    # Find the maximum count\n",
    "    max_count = max(string_counts.values())\n",
    "    \n",
    "    # Find all strings that have the maximum count\n",
    "    most_common_strings = [string for string, count in string_counts.items() if count == max_count]\n",
    "    \n",
    "    return most_common_strings, max_count\n",
    "\n",
    "def label_outliers(df: pd.DataFrame, columns: list, threshold: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds a new column 'Outlier' to the DataFrame. Marks columns as outliers if any pairwise comparison\n",
    "    score is below the threshold. For multiple columns, combines the names of columns identified as outliers.\n",
    "    \n",
    "    :param df: The input DataFrame.\n",
    "    :param columns: A list of column names used in pairwise comparisons.\n",
    "    :param threshold: The threshold value for outlier detection.\n",
    "    :return: The DataFrame with the new 'Outlier' column.\n",
    "    \"\"\"\n",
    "    # Initialize a dictionary to hold outlier status for each row\n",
    "    outlier_dict = {col: [] for col in columns}\n",
    "    \n",
    "    # Determine which columns should be considered based on the threshold\n",
    "    for index, row in df.iterrows():\n",
    "        outlier_columns = set()\n",
    "        outlier_column_info = []\n",
    "        for col in columns:\n",
    "            if row[col] < threshold:\n",
    "                outlier_columns.add(col)\n",
    "                for col2 in col.split(SEPERATOR):\n",
    "                    outlier_column_info.append(col2)\n",
    "        # # Update outlier_dict for this row\n",
    "        # for col in outlier_columns:\n",
    "        #     outlier_dict[col].append(True)\n",
    "        # if not outlier_columns:\n",
    "        #     outlier_dict[col].append(False)\n",
    "        # \n",
    "\n",
    "        df.at[index, 'Outlier Response'] = ', '.join([column_name for column_name in find_max_count(outlier_column_info)[0]])\n",
    "        # df['Outlier Response'] = ', '.join(outlier_column_info)\n",
    "    # Create the 'Outlier' column as a combination of the column names that are outliers\n",
    "    df['Outlier'] = df[columns].apply(lambda row: any(value < threshold for value in row), axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def apply_color_to_outliers(output_excel: str, df: pd.DataFrame, columns: list, threshold: float):\n",
    "    \"\"\"\n",
    "    Applies light red color formatting to cells below the threshold in the outlier columns.\n",
    "\n",
    "    :param output_excel: The Excel file to apply formatting to.\n",
    "    :param df: The DataFrame containing the data.\n",
    "    :param columns: The list of column names used for outlier detection.\n",
    "    :param threshold: The threshold value for outlier detection.\n",
    "    \"\"\"\n",
    "    # Load the Excel file\n",
    "    wb = load_workbook(output_excel)\n",
    "    ws = wb.active\n",
    "\n",
    "    # Define a light red fill for cells below the threshold\n",
    "    red_fill = PatternFill(start_color=\"FFCCCC\", end_color=\"FFCCCC\", fill_type=\"solid\")\n",
    "\n",
    "    # Apply the color to the relevant cells\n",
    "    for col in columns:\n",
    "        for row in range(2, len(df) + 2):  # Excel rows start at 1, skip the header\n",
    "            cell_value = ws[f'{col}{row}'].value\n",
    "            if isinstance(cell_value, (int, float)) and cell_value < threshold:\n",
    "                ws[f'{col}{row}'].fill = red_fill\n",
    "\n",
    "    # Save the workbook with the new formatting\n",
    "    wb.save(output_excel)\n",
    "    \n",
    "def save_outliers_to_excel(input_excel: str, columns: list, threshold: float, output_excel: str = None):\n",
    "    \"\"\"\n",
    "    Reads the first sheet of an Excel file, adds pairwise BERT F1 scores, labels outliers,\n",
    "    creates a second sheet with only outliers, and saves the updated DataFrame back to Excel.\n",
    "    \n",
    "    :param input_excel: Path to the input Excel file.\n",
    "    :param columns: A list of four column names to compare pairwise.\n",
    "    :param threshold: The threshold value for outlier detection.\n",
    "    :param output_excel: Path to the output Excel file. If None, overwrites the input file.\n",
    "    \"\"\"\n",
    "    # Step 1: Read the first sheet of the Excel file\n",
    "    \n",
    "    df = read_excel_first_sheet(input_excel)\n",
    "    \n",
    "    # Step 2: Add pairwise BERT F1 scores to the DataFrame\n",
    "    df = add_pairwise_bert_f1_to_dataframe(df, columns)\n",
    "    \n",
    "    # Generate BERT F1 score columns for outlier detection\n",
    "    score_columns = [f\"{col1}{SEPERATOR}{col2}\" for col1, col2 in combinations(columns, 2)]\n",
    "    \n",
    "    # Step 3: Label outliers\n",
    "    if threshold:\n",
    "        df = label_outliers(df, score_columns, threshold)\n",
    "    \n",
    "    # Create a DataFrame with only outliers\n",
    "    # outliers_df = df[df['Outlier'] != 'FALSE']\n",
    "    \n",
    "    # Step 4: Save the updated DataFrame and outliers to Excel\n",
    "    if output_excel is None:\n",
    "        output_excel = input_excel\n",
    "    \n",
    "    with pd.ExcelWriter(output_excel, engine='openpyxl') as writer:\n",
    "        # Save the main DataFrame with 'Outlier' column\n",
    "        df.to_excel(writer, index=False, sheet_name='Sheet1')\n",
    "        \n",
    "        # Save the outliers DataFrame to a new sheet\n",
    "        # outliers_df.to_excel(writer, index=False, sheet_name='Outliers')\n",
    "    apply_color_to_outliers(output_excel, df, score_columns, threshold)\n",
    "    print(f\"Updated Excel file saved to {output_excel}\")\n",
    "\n",
    "# Example usage:\n",
    "# save_outliers_to_excel('input.xlsx', ['col1', 'col2', 'col3', 'col4'], 0.7)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-10T20:50:37.133734Z",
     "start_time": "2024-09-10T20:50:37.119031Z"
    }
   },
   "id": "8e1a1fe8553c406b",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Rephrased query.1', 'Rephrased query.2'), ('Rephrased query.1', 'Rephrased query.3'), ('Rephrased query.1', 'Rephrased query.4'), ('Rephrased query.2', 'Rephrased query.3'), ('Rephrased query.2', 'Rephrased query.4'), ('Rephrased query.3', 'Rephrased query.4')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/45/606m4h496zx145vhz0ndd4f40000gp/T/ipykernel_3847/1646262522.py:32: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[index, 'Outlier Response'] = ', '.join(list(set([c for c in outlier_column_info if outlier_column_info.count(c) >= 2])))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Excel file saved to consistency_rephrased_query.xlsx\n"
     ]
    }
   ],
   "source": [
    "save_outliers_to_excel('consistency_9_11.xlsx', ['Rephrased query.1', 'Rephrased query.2', 'Rephrased query.3', 'Rephrased query.4'], 0.9, 'consistency_rephrased_query.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-11T22:17:44.595031Z",
     "start_time": "2024-09-11T22:17:15.575429Z"
    }
   },
   "id": "3128ef78f4cba34",
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Response_1', 'Response_2'), ('Response_1', 'Response_3'), ('Response_1', 'Response_4'), ('Response_2', 'Response_3'), ('Response_2', 'Response_4'), ('Response_3', 'Response_4')]\n",
      "Updated Excel file saved to consistency_9_11.xlsx\n"
     ]
    }
   ],
   "source": [
    "save_outliers_to_excel('consistency.xlsx', ['Response_1', 'Response_2', 'Response_3', 'Response_4'], 0.7, 'consistency_9_11.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-11T21:54:35.048363Z",
     "start_time": "2024-09-11T21:50:11.762028Z"
    }
   },
   "id": "850e43aad14aa5fa",
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "[('Response', 'Correct Answer')]\n",
      "4\n",
      "Updated Excel file saved to nvinfo_stg_sep10.xlsx\n"
     ]
    }
   ],
   "source": [
    "save_outliers_to_excel('nvinfo_stg_sep10.xlsx', ['Response', 'Correct Answer'], None, 'nvinfo_stg_sep10.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-10T20:46:47.809558Z",
     "start_time": "2024-09-10T20:45:58.266932Z"
    }
   },
   "id": "962086c3f6b17f09",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Response', 'Response Reference')]\n",
      "Updated Excel file saved to nvinfo_stg_sep10.xlsx\n"
     ]
    }
   ],
   "source": [
    "save_outliers_to_excel('nvinfo_stg_sep10.xlsx', ['Response', 'Response Reference'], 0.7, 'nvinfo_stg_sep10.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-10T20:51:35.481122Z",
     "start_time": "2024-09-10T20:50:49.704990Z"
    }
   },
   "id": "f9d416266499c78a",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['asa']"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-10T21:29:45.121297Z",
     "start_time": "2024-09-10T21:29:45.092857Z"
    }
   },
   "id": "3f4f447678eaa01c",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "file_names = [\"after_1.xlsx\", \"after_2.xlsx\", \"after_3.xlsx\",\"after_4.xlsx\"]\n",
    "\n",
    "evaluators =  [\n",
    "        {\n",
    "          \"columns\": [\n",
    "            \"Chat History Query\",\n",
    "            \"Rephrased query\",\n",
    "            \"Ranked IR Chunks\",\n",
    "            \"Response\"\n",
    "          ],\n",
    "          \"scorers\": [\n",
    "            \"bert\"\n",
    "          ],\n",
    "          \"threshold\": 0.7\n",
    "        },\n",
    "        {\n",
    "          \"columns\": [\n",
    "            \"Pre-facto experts\"\n",
    "          ],\n",
    "          \"scorers\": [\n",
    "            \"em\"\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "columns = evaluators[0].get(\"columns\") + evaluators[1].get(\"columns\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-11T04:21:28.451238Z",
     "start_time": "2024-09-11T04:21:28.445799Z"
    }
   },
   "id": "16e9cfd2deadc73f",
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[74], line 237\u001B[0m\n\u001B[1;32m    234\u001B[0m SORT_COLUMN \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mID\u001B[39m\u001B[38;5;124m\"\u001B[39m  \u001B[38;5;66;03m# Replace with the actual name of the column to sort by, or leave as None to use the first column.\u001B[39;00m\n\u001B[1;32m    236\u001B[0m \u001B[38;5;66;03m# Run the process\u001B[39;00m\n\u001B[0;32m--> 237\u001B[0m df_final \u001B[38;5;241m=\u001B[39m \u001B[43mprocess_files\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile_names\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madditional_columns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcomparison_columns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mCOLUMN_SUFFIX_SEPARATOR\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msort_column\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mSORT_COLUMN\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    238\u001B[0m \u001B[38;5;28mprint\u001B[39m(df_final)\n\u001B[1;32m    240\u001B[0m \u001B[38;5;66;03m# Optionally, save the result to Excel\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[74], line 216\u001B[0m, in \u001B[0;36mprocess_files\u001B[0;34m(file_names, additional_columns, comparison_columns, column_suffix_separator, sort_column)\u001B[0m\n\u001B[1;32m    213\u001B[0m     comparison_dataframes\u001B[38;5;241m.\u001B[39mappend(comparison_data)\n\u001B[1;32m    215\u001B[0m \u001B[38;5;66;03m# Step 4: Align comparison columns side by side with pairwise comparisons and outliers\u001B[39;00m\n\u001B[0;32m--> 216\u001B[0m df_aligned_comparison \u001B[38;5;241m=\u001B[39m \u001B[43malign_comparison_columns\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcomparison_dataframes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcomparison_columns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumn_suffix_separator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m \u001B[38;5;66;03m# Step 5: Merge additional_data with aligned comparison columns\u001B[39;00m\n\u001B[1;32m    219\u001B[0m df_final \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([additional_data, df_aligned_comparison], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "Cell \u001B[0;32mIn[74], line 187\u001B[0m, in \u001B[0;36malign_comparison_columns\u001B[0;34m(dfs, comparison_columns, column_suffix_separator)\u001B[0m\n\u001B[1;32m    185\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, col_label \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(col_labels):\n\u001B[1;32m    186\u001B[0m         outlier_col_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcol_label\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m Outlier\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 187\u001B[0m         aligned_dfs[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m][outlier_col_name] \u001B[38;5;241m=\u001B[39m \u001B[43maligned_dfs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrow\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcol_label\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m<\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mthresholds\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcol\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    189\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pd\u001B[38;5;241m.\u001B[39mconcat(aligned_dfs, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/Git/NVBot/zsh/venvs/venv/lib/python3.10/site-packages/pandas/core/frame.py:10374\u001B[0m, in \u001B[0;36mDataFrame.apply\u001B[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001B[0m\n\u001B[1;32m  10360\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapply\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m frame_apply\n\u001B[1;32m  10362\u001B[0m op \u001B[38;5;241m=\u001B[39m frame_apply(\n\u001B[1;32m  10363\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m  10364\u001B[0m     func\u001B[38;5;241m=\u001B[39mfunc,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m  10372\u001B[0m     kwargs\u001B[38;5;241m=\u001B[39mkwargs,\n\u001B[1;32m  10373\u001B[0m )\n\u001B[0;32m> 10374\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapply\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Git/NVBot/zsh/venvs/venv/lib/python3.10/site-packages/pandas/core/apply.py:916\u001B[0m, in \u001B[0;36mFrameApply.apply\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    913\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw:\n\u001B[1;32m    914\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_raw(engine\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine, engine_kwargs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine_kwargs)\n\u001B[0;32m--> 916\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Git/NVBot/zsh/venvs/venv/lib/python3.10/site-packages/pandas/core/apply.py:1063\u001B[0m, in \u001B[0;36mFrameApply.apply_standard\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1061\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_standard\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m   1062\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpython\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m-> 1063\u001B[0m         results, res_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_series_generator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1064\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1065\u001B[0m         results, res_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_series_numba()\n",
      "File \u001B[0;32m~/Git/NVBot/zsh/venvs/venv/lib/python3.10/site-packages/pandas/core/apply.py:1081\u001B[0m, in \u001B[0;36mFrameApply.apply_series_generator\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1078\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m option_context(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmode.chained_assignment\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m   1079\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(series_gen):\n\u001B[1;32m   1080\u001B[0m         \u001B[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001B[39;00m\n\u001B[0;32m-> 1081\u001B[0m         results[i] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1082\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(results[i], ABCSeries):\n\u001B[1;32m   1083\u001B[0m             \u001B[38;5;66;03m# If we have a view on v, we need to make a copy because\u001B[39;00m\n\u001B[1;32m   1084\u001B[0m             \u001B[38;5;66;03m#  series_generator will swap out the underlying data\u001B[39;00m\n\u001B[1;32m   1085\u001B[0m             results[i] \u001B[38;5;241m=\u001B[39m results[i]\u001B[38;5;241m.\u001B[39mcopy(deep\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "Cell \u001B[0;32mIn[74], line 187\u001B[0m, in \u001B[0;36malign_comparison_columns.<locals>.<lambda>\u001B[0;34m(row)\u001B[0m\n\u001B[1;32m    185\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, col_label \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(col_labels):\n\u001B[1;32m    186\u001B[0m         outlier_col_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcol_label\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m Outlier\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 187\u001B[0m         aligned_dfs[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m][outlier_col_name] \u001B[38;5;241m=\u001B[39m aligned_dfs[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m row: \u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcol_label\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m<\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mthresholds\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcol\u001B[49m\u001B[43m]\u001B[49m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    189\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pd\u001B[38;5;241m.\u001B[39mconcat(aligned_dfs, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[0;31mTypeError\u001B[0m: '<' not supported between instances of 'str' and 'float'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def load_and_sort_excel(file_name: str, sort_column: str = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads and sorts the Excel file by the specified sort column (default is the first column).\n",
    "    \n",
    "    :param file_name: The path to the Excel file.\n",
    "    :param sort_column: The column name to sort by. If None, sorts by the first column.\n",
    "    :return: Sorted DataFrame.\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(file_name)\n",
    "    \n",
    "    # Sort by the specified column, or the first column if not specified\n",
    "    if sort_column is None:\n",
    "        sort_column = df.columns[0]  # Sort by the first column if not specified\n",
    "    \n",
    "    df_sorted = df.sort_values(by=sort_column)  # Sort by the specified column\n",
    "    return df_sorted\n",
    "\n",
    "def extract_columns(df: pd.DataFrame, columns: list, file_index: int = None, column_suffix_separator: str = \"_\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts columns from the DataFrame and labels them based on the file index.\n",
    "    \n",
    "    :param df: Input DataFrame.\n",
    "    :param columns: List of column names to extract.\n",
    "    :param file_index: Index to append to the column name.\n",
    "    :param column_suffix_separator: String to use as the separator between column names and file index.\n",
    "    :return: Extracted DataFrame with renamed columns.\n",
    "    \"\"\"\n",
    "    extracted_columns = {}\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            col_label = f\"{col}{column_suffix_separator}{file_index}\" if file_index is not None else col\n",
    "            extracted_columns[col_label] = df[col]\n",
    "        else:\n",
    "            print(f\"Error: Column '{col}' not found in file {file_index}\")\n",
    "    return pd.DataFrame(extracted_columns)\n",
    "\n",
    "COLUMN_COMPARISON_SEPARATOR = \":\"\n",
    "\n",
    "def find_max_count(strings):\n",
    "    \"\"\"\n",
    "    Finds the most common strings in a list.\n",
    "    \"\"\"\n",
    "    string_counts = Counter(strings)\n",
    "    max_count = max(string_counts.values())\n",
    "    most_common_strings = [string for string, count in string_counts.items() if count >= max_count]\n",
    "    return most_common_strings, max_count\n",
    "\n",
    "\n",
    "def calculate_tfidf_similarity(list1, list2):\n",
    "    \"\"\"\n",
    "    Calculate similarity between two lists using TF-IDF and Cosine Similarity.\n",
    "    The order of the items in the list matters.\n",
    "    \"\"\"\n",
    "    # Join list items into a single string, preserving order\n",
    "    list1_str = ' '.join(list1)\n",
    "    list2_str = ' '.join(list2)\n",
    "    \n",
    "    # Use TF-IDF vectorizer to convert text to vectors\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([list1_str, list2_str])\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
    "    \n",
    "    return cosine_sim[0][0]\n",
    "\n",
    "\n",
    "def add_bert_f1_to_dataframe(df: pd.DataFrame, col1: str, col2: str, score_col: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds a new column with BERT F1 scores to the DataFrame.\n",
    "    \n",
    "    :param df: DataFrame containing the two columns to compare.\n",
    "    :param col1: Name of the first column (ground truth).\n",
    "    :param col2: Name of the second column (predicted).\n",
    "    :param score_col: Name of the column to store the BERT F1 score.\n",
    "    :return: DataFrame with the BERT F1 score column added.\n",
    "    \"\"\"\n",
    "    # Extract the ground truth and predicted columns from the DataFrame\n",
    "    gt_list = [str(c) for c in df[col1].tolist()]\n",
    "    pt_list = [str(c) for c in df[col2].tolist()]\n",
    "    \n",
    "    # Calculate BERT F1 scores\n",
    "    _, _, f1 = score(gt_list, pt_list, lang=\"en\", model_type=\"bert-base-uncased\", batch_size=64)\n",
    "    \n",
    "    # Convert the torch.Tensor to a list and add it as a new column\n",
    "    df[score_col] = f1.tolist()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def add_similarity_score(df: pd.DataFrame, col1: str, col2: str, score_col: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds a new column with custom similarity scores to the DataFrame.\n",
    "    Handles lists, dictionaries, and regular strings.\n",
    "    \n",
    "    :param df: DataFrame containing the two columns to compare.\n",
    "    :param col1: Name of the first column (ground truth).\n",
    "    :param col2: Name of the second column (predicted).\n",
    "    :param score_col: Name of the column to store the similarity score.\n",
    "    :return: DataFrame with the similarity score column added.\n",
    "    \"\"\"\n",
    "    similarity_scores = []\n",
    "\n",
    "    sim_score = None\n",
    "    for idx, row in df.iterrows():\n",
    "        value1 = row[col1]\n",
    "        value2 = row[col2]\n",
    "\n",
    "        # Check if both values are lists\n",
    "        if isinstance(value1, list):\n",
    "            sim_score = calculate_tfidf_similarity(value1, value2)\n",
    "        \n",
    "        # Check if both values are dictionaries\n",
    "        elif isinstance(value1, dict):\n",
    "            sim_score = 0\n",
    "            if set(value1.keys()) == set(value2.keys()):\n",
    "                \n",
    "                dict1 = value1\n",
    "                dict2 = value2\n",
    "            \n",
    "                sim_scores = []\n",
    "                for key in dict1.keys():\n",
    "                    v1 = dict1[key] if isinstance(dict1[key], list) else [str(value1)]\n",
    "                    v2 = dict2[key] if isinstance(dict2[key], list) else [str(value1)]\n",
    "        \n",
    "                    _, _, key_f1 = score(v1, v2, lang=\"en\", model_type=\"bert-base-uncased\", batch_size=64)\n",
    "                    sim_scores.append(key_f1[0].item())\n",
    "        \n",
    "                sim_score = sum(sim_scores) / len(sim_scores)\n",
    "        \n",
    "        similarity_scores.append(sim_score)\n",
    "        \n",
    "    if len(similarity_scores) == 0:\n",
    "  \n",
    "        _, _, f1 = score([str(c) for c in df[col1].tolist()], [str(c) for c in df[col1].tolist()], lang=\"en\", model_type=\"bert-base-uncased\", batch_size=64)\n",
    "        similarity_scores = f1.tolist()\n",
    "        \n",
    "    # Add the similarity score to the DataFrame\n",
    "    df[score_col] = similarity_scores\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def align_comparison_columns(dfs: list, comparison_columns: dict, column_suffix_separator: str = \"_\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aligns comparison columns from all files side by side, ensuring they are grouped for easy comparison.\n",
    "    Adds pairwise comparisons and outlier columns using BERT F1 scores.\n",
    "    \n",
    "    :param dfs: List of DataFrames (from each file).\n",
    "    :param comparison_columns: Dictionary where keys are column names and values are thresholds.\n",
    "    :param column_suffix_separator: Separator used for naming columns.\n",
    "    :return: A DataFrame with aligned comparison columns and outlier detection.\n",
    "    \"\"\"\n",
    "    aligned_columns = pd.DataFrame()\n",
    "    thresholds = {key: comparison_columns.get(key, 0.7) for key in comparison_columns}\n",
    "    \n",
    "    # Collect aligned comparison columns\n",
    "    aligned_dfs = []\n",
    "    for col in comparison_columns:\n",
    "        aligned_col_group = []\n",
    "        col_labels = []  # To keep track of column labels\n",
    "        for i, df in enumerate(dfs, start=1):\n",
    "            col_label = f\"{col}{column_suffix_separator}{i}\"\n",
    "            if col_label in df.columns:\n",
    "                aligned_col_group.append(df[col_label])\n",
    "                col_labels.append(col_label)\n",
    "            else:\n",
    "                print(f\"Error: Column '{col_label}' not found in file {i}\")\n",
    "        \n",
    "        # Concatenate the aligned columns for this specific comparison column\n",
    "        aligned_dfs.append(pd.concat(aligned_col_group, axis=1))\n",
    "        \n",
    "        # Step 1: Pairwise comparison for the aligned columns using BERT F1 scores\n",
    "        if len(col_labels) > 1:\n",
    "            for i, col1 in enumerate(col_labels):\n",
    "                for col2 in col_labels[i+1:]:\n",
    "                    new_col_name = f\"{col1}{COLUMN_COMPARISON_SEPARATOR}{col2}\"\n",
    "                    aligned_dfs[-1] = add_similarity_score(aligned_dfs[-1], col1, col2, new_col_name)\n",
    "        \n",
    "        # Step 2: Detect outliers based on BERT F1 score and thresholds\n",
    "        for i, col_label in enumerate(col_labels):\n",
    "            outlier_col_name = f\"{col_label} Outlier\"\n",
    "            aligned_dfs[-1][outlier_col_name] = aligned_dfs[-1].apply(lambda row: row[col_label] < thresholds[col], axis=1)\n",
    "    \n",
    "    return pd.concat(aligned_dfs, axis=1)\n",
    "\n",
    "def process_files(file_names: list, additional_columns: list, comparison_columns: dict, column_suffix_separator: str = \"_\", sort_column: str = None):\n",
    "    \"\"\"\n",
    "    Processes multiple Excel files, extracts specified columns, and merges them into one DataFrame.\n",
    "    \n",
    "    :param file_names: List of Excel file paths.\n",
    "    :param additional_columns: List of columns to extract from the first file.\n",
    "    :param comparison_columns: Dictionary with column names as keys and threshold values as values.\n",
    "    :param column_suffix_separator: Separator used for naming columns from different files.\n",
    "    :param sort_column: The column to sort each DataFrame by.\n",
    "    :return: A merged DataFrame with sorted and extracted data, including outlier detection.\n",
    "    \"\"\"\n",
    "    # Step 1: Load and sort the first file (additional_columns)\n",
    "    df_first = load_and_sort_excel(file_names[0], sort_column=sort_column)\n",
    "    \n",
    "    # Step 2: Extract additional_columns from the first file\n",
    "    additional_data = extract_columns(df_first, additional_columns)\n",
    "    \n",
    "    # Step 3: Loop through the rest of the files and extract comparison_columns\n",
    "    comparison_dataframes = []\n",
    "    for i, file_name in enumerate(file_names[1:], start=1):\n",
    "        df = load_and_sort_excel(file_name, sort_column=sort_column)\n",
    "        comparison_data = extract_columns(df, list(comparison_columns.keys()), i, column_suffix_separator)\n",
    "        comparison_dataframes.append(comparison_data)\n",
    "    \n",
    "    # Step 4: Align comparison columns side by side with pairwise comparisons and outliers\n",
    "    df_aligned_comparison = align_comparison_columns(comparison_dataframes, comparison_columns, column_suffix_separator)\n",
    "    \n",
    "    # Step 5: Merge additional_data with aligned comparison columns\n",
    "    df_final = pd.concat([additional_data, df_aligned_comparison], axis=1)\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "# Example usage:\n",
    "file_names = [\"after_1.xlsx\", \"after_2.xlsx\", \"after_3.xlsx\", \"after_4.xlsx\"]\n",
    "additional_columns = ['Query', 'Correct Answer']\n",
    "comparison_columns = {\n",
    "    'Chat History Query': 0.7, \n",
    "    'Rephrased query': 0.7, \n",
    "    'Ranked IR Chunks': 0.7, \n",
    "    'Response': 0.7, \n",
    "    'Pre-facto experts': 0.7\n",
    "}\n",
    "COLUMN_SUFFIX_SEPARATOR = \"_\"\n",
    "SORT_COLUMN = \"ID\"  # Replace with the actual name of the column to sort by, or leave as None to use the first column.\n",
    "\n",
    "# Run the process\n",
    "df_final = process_files(file_names, additional_columns, comparison_columns, COLUMN_SUFFIX_SEPARATOR, sort_column=SORT_COLUMN)\n",
    "print(df_final)\n",
    "\n",
    "# Optionally, save the result to Excel\n",
    "df_final.to_excel('merged_output_with_outliers.xlsx', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-11T07:44:05.303318Z",
     "start_time": "2024-09-11T07:43:59.062965Z"
    }
   },
   "id": "ec8f068470bfb7fe",
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# Optionally, save the result to Excel\n",
    "df_merged.to_excel('merged_output1.xlsx', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf29ecb9d60f3899"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
